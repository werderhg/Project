---
title: "Project Machine Learning Coursera Hopekins"
author: "Harry Werder"
date: "Thursday, July 09, 2015"
output: html_document
---

### Introduction
We will build a model to predict the outcome "classe" with the levels A,B,C,D,E based on covariants (predictors) from the Human Activity Recognition data.
The data for this project comes from this source: http://groupware.les.inf.puc-rio.br/har. 

###1. Step: Set-up of environment in R

```{r}
setwd("H:/Eigene Dateien/A-Coursera/Stat Kurs/8-Machine Learning/Project") #working directory
rm(list=ls()) #clean the variables
library(ggplot2); library(caret); library(randomForest) #packages used

#Use multiple cores of the processor
# library(doParallel) #install.packages("doParallel")
# registerDoParallel(cores=2)
```


### 2. Step: Loading the data
We load the data and replace all "","NA", "#DIV/0!" values with the NA value from R.
```{r}
rawdata <- read.csv("pml-training.csv", na.strings = c("", "NA", "#DIV/0!") )
```

### 3. Step: Clean the data and select covariant
We found out by reading the data description that the first seven columns are descriptions.
So we remove them from our raw data data. -(1:7).
```{r}
data <- rawdata[,-(1:7)]
```

We remove now the covariants that have more than 10% of missing data.

```{r}
# set the outcome aside
classe <- data$classe
    # remove the classe from the data
        #find the column with the covariants (predictors)
        aa<- colnames(data)=="classe"

    data <- data[,!aa]
# define a function for the removal
remove_cov <- function(x,y) { 
    shortdata <- x[ , colSums( is.na(x) ) <= y/100*nrow(x) ]
    bb <- c(i, ncol(shortdata))
    return(bb)
    }
bbb<- data.frame(percent=integer(),covariant=integer()) #initiate
# i is the percentage of NA's per column
for(i in 0:100) {
    bbb[i+1,1]<-remove_cov(data,i)[1]
    bbb[i+1,2]<-remove_cov(data,i)[2]
    }
#the plot tells us what percentage cut-off will reduce covariants
qplot(percent,covariant,data=bbb)

# create our reduced data
shortdata <- data[ , colSums( is.na(data) ) <= 10/100*nrow(data) ]

#reduce by PCA
cc<-data.frame(percent=integer(),components=integer())
for( i in 1:99) {
    pcaFit<-preProcess(shortdata, method=c("center", "scale", "pca"),thresh=i/100)
    cc[i,1]<- i
    cc[i,2]<-pcaFit$numComp
    }
qplot(percent,components,data=cc)

pcaFit95<-preProcess(shortdata, method=c("center", "scale", "pca"),thresh=0.95)
pcadata95<-predict(pcaFit95,shortdata)
pcaFit75<-preProcess(shortdata, method=c("center", "scale", "pca"),thresh=0.75)
pcadata75<-predict(pcaFit75,shortdata)

# add the outcome
shortdata$classe <- classe
pcadata95$classe<-classe
pcadata75$classe<-classe
```

We have reduced the number of covariants from **`r ncol(data) `** to **`r ncol(shortdata)-1 `**.

```{r}
yaa <- levels(shortdata$classe)
```
The outcome has the following levels **`r yaa`**.


### 4. Setting up our training and test datasets
We split the data into a training set (70%) and a test set (30%).

```{r}
set.seed(400)
inTrain <-createDataPartition(y=shortdata$classe, p=0.7, list=FALSE)
training <- shortdata[inTrain,]; 
testing <- shortdata[-inTrain,]

inTrain95 <-createDataPartition(y=pcadata95$classe, p=0.3, list=FALSE)
training95 <- pcadata95[inTrain95,]; 
testing95 <- pcadata95[-inTrain95,]

inTrain75 <-createDataPartition(y=pcadata75$classe, p=0.3, list=FALSE)
training75 <- pcadata75[inTrain75,]; 
testing75 <- pcadata75[-inTrain75,]



```

We have now a training data set with **`r dim(training) `** rows.

### 5. Step: Calculate the model

#### 5.1. Using k-nearest neighbors (knn)
knn-methods is a very simple method. The main parameter is the number of neighbors (=k). 

```{r}
set.seed(400)
ctrl <- trainControl(method="repeatedcv",repeats = 3) #,classProbs=TRUE,summaryFunction = twoClassSummary)
# knnFit <- train(classe ~ ., data = training, method = "knn", trControl = ctrl, preProcess = c("center","scale"), tuneLength = 20)

# saveRDS(knnFit, file="knnFit7030.rds") #save the result
knnFit <- readRDS("knnFit7030.rds")

```

The following plots tell us more. (training data)
```{r}
knnplot<- plot(knnFit)
```

The best accuracy is achieved with k=5. We note that the in-sample accuracy is above 95%.


#### 5.2 Using random forest method

We chosen  random tree as the algorith because it is recognized as a good performer.
```{r}
# rfFit <- train( classe ~ ., method="rf", prox=TRUE, data=training)
# saveRDS(rfFit, file="rfFit7030.rds")
rfFit <-readRDS("rfFit7030.rds")
tt <- rfFit$finalModel
```
The resulting model
```{r}
tt
```
OOB looks great with 1.75%!!

We also use next our pca-reduced dataset with less covariants with random tree.
One model with 75% variance explained by pca and the other with 95% variance explained.
```{r}
# it is very timeconsuming to do the train, so I show code and load from file the result
# rfFit95 <- train( classe ~ ., method="rf", prox=TRUE, data=training95)
# saveRDS(rfFit95, file="rfFit953070.rds")
rfFit95 <-readRDS("rfFit953070.rds")
tt95 <- rfFit95$finalModel

# rfFit75 <- train( classe ~ ., method="rf", prox=TRUE, data=training75)
# saveRDS(rfFit75, file="rfFit753070.rds")
rfFit75 <- readRDS("rfFit753070.rds")
tt75 <- rfFit75$finalModel
```

The resulting model for 75% variance explained pca:
```{r}
tt75
```
The resulting model for 75% variance explained pca:
```{r}
tt95
```

OOB estimate of error rate is for both model low but fare away from the non adjusted.


### 5. Testing the model with the test data

We use now our testing data to see how good our model works.

Evaluation for pca-reduced models
```{r}

#our model with PCA at 95% explained, training 30% and 70% test
testaa<- colnames(testing)=="classe"
test95<-testing[,!(testaa)]
testpcadata95<-predict(pcaFit95,test95)
testpcadata95$classe <-testing$classe
pred95<-predict(rfFit95,testpcadata95)
test95conf <- confusionMatrix(testing$classe,pred95)
accrfpca95<-test95conf$overall[1]

#our model with PCA at 75% explained, training 20% and 80% test
test75<-testing[,!(testaa)]
testpcadata75<-predict(pcaFit75,test75)
testpcadata75$classe <-testing$classe
pred75<-predict(rfFit75,testpcadata75)
test75conf <- confusionMatrix(testing$classe,pred75)
accrfpca75<-test75conf$overall[1]
```

Accuracy is for the 75% variance explained pca: **`r accrfpca75 `**
Accuracy is for the 95% variance explained pca: **`r accrfpca95 `**

Now we test with the full random forest model:
```{r}
test100<-testing[,!(testaa)]

predrf<-predict(rfFit,test100)
testrfconf <- confusionMatrix(testing$classe,predrf)
accrf<-testrfconf$overall[1]
```

Accuracy is for the full random forest model predication: **`r accrf `**

Now we test with the k-nearest neighbors:
```{r}
# using the test data
# predknn<- predict(knnFit,testing)
# saveRDS(predknn, file="knnFitprdict.rds")
predknn <- readRDS("knnFitprdict.rds")
ttknn<-confusionMatrix(testing$classe, predknn)
accknn<-ttknn$overall[1]
```
Accuracy is for the knn predication: **`r accknn `**

Summary
We recommend to use random forest model with accuracy of **`r accrf `**



